{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Maximum Likelihood Estimation\n",
    "(by Tevfik Aytekin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import factorial as f\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple Problem\n",
    "\n",
    "Suppose that we have a biased coin X. A biased coin means that the probability of a head is not 0.5. Suppose that we do not know the bias of X. In order to estimate its bias we toss the coin 10 times and the output is as follows:\n",
    "\n",
    "T, T, H, T, H, H, H, T, H, H\n",
    "\n",
    "What might be our best guess for the bias of X? \n",
    "\n",
    "You might think that since there are 4 Tails and 6 Heads in the sample output our best estimation for probabiliy of a head (let us call it $\\theta$) is 0.6. Actually, this reasoning can be made more formal as follows:\n",
    "\n",
    "### Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "In order to understand MLE we need to first understand the likelihood function. Let $X$ be a discrete random variable whose values are H and T with probability $\\theta$ for H (hence 1-$\\theta$ for T) .\n",
    "\n",
    "Remember that in our problem we toss a coin 10 times and get 4 heads. What is the most probable value of $\\theta$ to give this outcome? For example, is $\\theta=0.1$ or $\\theta=0.5$ more probable? To find the answer let us formalize the problem.\n",
    "\n",
    "Let $X_1, X_2, X_3, ..., X_n$ denote a random sample where the probability mass (or density) function of each $X_i$ which is $f(x_i;\\theta)$. Here, $x_i$ is an observed value of $X_i$ and $\\theta$ is some parameter (which can be more than one) of the pmf. Then the joint probability mass (or density) function of $X_1, X_2, X_3, ..., X_n$, which is called the likelihood function and denoted by $L(\\theta)$, is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L(\\theta)&=P(X_1=x_1, X_2=x_2, X_3=x_3, ...,X_n=x_n) \\\\\n",
    "&= f(x_1;\\theta)f(x_2;\\theta)f(x_3;\\theta)...f(x_n;\\theta) \\\\ \n",
    "&= \\prod_{i=1}^{n}f(x_i;\\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now, let us find the likelihood function for our specific example. In our example the pmf of each $X_i$ can be described as a Bernoulli random variable with values 1 (for H) and 0 (for T) and with an unknown parameter $\\theta$ and whose pmf is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x_i;\\theta) &= \\theta^{x_i}(1-\\theta)^{1-x_i}\\\\ \n",
    "\\implies L(\\theta)&=\\prod_{i=1}^{n}\\theta^{x_i}(1-\\theta)^{1-x_i}\\\\\n",
    "&= \\theta^{x_1}(1-\\theta)^{1-x_1}\\theta^{x_2}(1-\\theta)^{1-x_2}\\theta^{x_3}(1-\\theta)^{1-x_3}...\\theta^{x_n}(1-\\theta)^{1-x_n}\\\\\n",
    "&= \\theta^{\\sum x_i}(1-\\theta)^{n-\\sum x_i}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Or simply, if there are $k$ heads in $n$ tosses, we can write the likelihood as:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\theta^k(1-\\theta)^{(n-k)}\n",
    "$$ \n",
    "\n",
    "To find the most probable value of $\\theta$ means to find the value of $\\theta$ which maximizes the likelihood function (hence the name MLE). Now the rest is some calculus.\n",
    "\n",
    "For convinience we will take the log of $L$ (called the loglikelihood) since it will not change the maximizing value and it is easier to differentiate. \n",
    "\n",
    "$$\n",
    "logL(\\theta) =  klog\\theta + (n-k)log(1-\\theta)\n",
    "$$\n",
    "\n",
    "Now take the derivative with respect to $\\theta$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial logL(\\theta)}{\\partial \\theta} =  \\frac{-k}{\\theta} + \\frac{(n-k)}{1-\\theta)}\n",
    "$$\n",
    "\n",
    "And solve by setting to zero\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{-k}{\\theta} + \\frac{(n-k)}{1-\\theta)} &= 0 \\\\\n",
    "\\implies -k(1-\\theta) + (n-k)\\theta &= 0 \\\\\n",
    "\\implies -k + \\theta k + \\theta n -\\theta k &= 0 \\\\\n",
    "\\implies \\theta &= \\frac{k}{n}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So, when $n=10$ and $k=4$, the most probably value of $\\theta=0.4$. This result conforms our initial intution. Note that in the above derivation we assumed that $L(\\theta)$ is a convex function.\n",
    "\n",
    "MLE is a very general technique and it can be applied to any parameter estimation problem given a sample output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example\n",
    "\n",
    "In the following example we see observe values as we press the next observation button. These observations might be anything in the world. One thing we can do is to make probabilistic modeling. For example, we can assume that the values are the outcomes of a random process which is normally distributed with unknown parameters. This is a common approach, assume a general probabilistic model (possibly with parameters) and try to estimate the values of the parameters given some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def change_text():\n",
    "    value1 = int(np.random.normal(100, 20))\n",
    "    label1.config(text=str(value1))\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"One Variable\")\n",
    "root.option_add(\"*Font\", \"Arial 16\")\n",
    "# Create a label for the first random value\n",
    "label1_text = tk.Label(root, text=\"Variable\")\n",
    "label1_text.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "# Create a label for displaying the first random value\n",
    "label1 = tk.Label(root)\n",
    "label1.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "\n",
    "# Create the button\n",
    "button = tk.Button(root, text=\"Next Observation\", command=change_text)\n",
    "button.grid(row=2, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import random\n",
    "\n",
    "def change_text():\n",
    "    value1 = random.randint(0, 100)\n",
    "    value2 = int(5*value1 + np.random.normal(0,10))\n",
    "    label1.config(text=str(value1))\n",
    "    label2.config(text=str(value2))\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Two Observations\")\n",
    "root.option_add(\"*Font\", \"Arial 16\")\n",
    "# Create a label for the first random value\n",
    "label1_text = tk.Label(root, text=\"Variable 1:\")\n",
    "label1_text.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "# Create a label for displaying the first random value\n",
    "label1 = tk.Label(root)\n",
    "label1.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "# Create a label for the second random value\n",
    "label2_text = tk.Label(root, text=\"Variable 2:\")\n",
    "label2_text.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "# Create a label for displaying the second random value\n",
    "label2 = tk.Label(root)\n",
    "label2.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "# Create the button\n",
    "button = tk.Button(root, text=\"Next Observation\", command=change_text)\n",
    "button.grid(row=2, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import random\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def change_text():\n",
    "    value1 = random.randint(0, 100)\n",
    "    value2 = int(sigmoid(-50 + 5*value1 + np.random.normal(0,10)))\n",
    "    label1.config(text=str(value1))\n",
    "    label2.config(text=str(value2))\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Two Observations\")\n",
    "root.option_add(\"*Font\", \"Arial 16\")\n",
    "# Create a label for the first random value\n",
    "label1_text = tk.Label(root, text=\"Variable 1:\")\n",
    "label1_text.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "# Create a label for displaying the first random value\n",
    "label1 = tk.Label(root)\n",
    "label1.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "# Create a label for the second random value\n",
    "label2_text = tk.Label(root, text=\"Variable 2:\")\n",
    "label2_text.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "# Create a label for displaying the second random value\n",
    "label2 = tk.Label(root)\n",
    "label2.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "# Create the button\n",
    "button = tk.Button(root, text=\"Next Observation\", command=change_text)\n",
    "button.grid(row=2, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
